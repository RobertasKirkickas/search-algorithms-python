{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b0e7f-d59d-4b86-89f9-d19b4525928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inline mode\n",
    "%matplotlib inline\n",
    "\n",
    "# Import necessary libraries\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import deque, namedtuple\n",
    "from queue import PriorityQueue\n",
    "\n",
    "# PGMPY - Bayesian Network related imports\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "from pgmpy.estimators import (\n",
    "    HillClimbSearch, \n",
    "    K2Score, \n",
    "    BicScore, \n",
    "    PC, \n",
    "    TreeSearch, \n",
    "    MmhcEstimator, \n",
    "    StructureEstimator\n",
    ")\n",
    "\n",
    "# Scikit-learn related imports\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# NLTK related imports for text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb53286-bc66-4b84-8cc7-e6782c2f4c70",
   "metadata": {},
   "source": [
    "Task 1 â€“ Search methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a77bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Node = namedtuple('Node', ['state', 'parent', 'action', 'path_cost']) # class is used to represent nodes in a graph-tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Graph class\n",
    "class Graph:\n",
    "    def __init__(self, structure):\n",
    "        # Initialize the Graph with a structure dictionary representing the adjacency list\n",
    "        self.structure = structure\n",
    "    \n",
    "    def successors(self, state):\n",
    "         # Retrieve and return the list of successors for a given state from the structure\n",
    "        return self.structure.get(state, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680dde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = {\n",
    "    'Ipswich': [('Colchester', 'Ipswich -> Colchester', 40), ('Bury St Edmunds', 'Ipswich -> Bury St Edmunds', 50), ('Norwich', 'Ipswich -> Norwich', 70), ('Chelmsford', 'Ipswich -> Chelmsford', 35)],\n",
    "    'Colchester': [('Chelmsford', 'Colchester -> Chelmsford', 30), ('Norwich', 'Colchester -> Norwich', 45), ('Felixstowe', 'Colchester -> Felixstowe', 60)],\n",
    "    'Norwich': [('Great Yarmouth', 'Norwich -> Great Yarmouth', 20), ('Lowestoft', 'Norwich -> Lowestoft', 40), ('Cambridge', 'Norwich -> Cambridge', 55), ('Thetford', 'Norwich -> Thetford', 65)],\n",
    "    'Bury St Edmunds': [('Cambridge', 'Bury St Edmunds -> Cambridge', 60), ('Colchester', 'Bury St Edmunds -> Colchester', 45), ('Stowmarket', 'Bury St Edmunds -> Stowmarket', 40)],\n",
    "    'Chelmsford': [('London', 'Chelmsford -> London', 40), ('Cambridge', 'Chelmsford -> Cambridge', 50), ('Harwich', 'Chelmsford -> Harwich', 55)],\n",
    "    'Lowestoft': [('Great Yarmouth', 'Lowestoft -> Great Yarmouth', 25), ('Yarmouth', 'Lowestoft -> Yarmouth', 45)],\n",
    "    'Great Yarmouth': [('Lowestoft', 'Great Yarmouth -> Lowestoft', 25), ('Norwich', 'Great Yarmouth -> Norwich', 20), ('Caister', 'Great Yarmouth -> Caister', 30)],\n",
    "    'Cambridge': [('London', 'Cambridge -> London', 50), ('Chelmsford', 'Cambridge -> Chelmsford', 50), ('Ely', 'Cambridge -> Ely', 30)],\n",
    "    'London': [('Chelmsford', 'London -> Chelmsford', 40), ('Cambridge', 'London -> Cambridge', 55), ('Colchester', 'London -> Colchester', 70)],\n",
    "    'Felixstowe': [('Colchester', 'Felixstowe -> Colchester', 60)],\n",
    "    'Thetford': [('Norwich', 'Thetford -> Norwich', 65)],\n",
    "    'Stowmarket': [('Bury St Edmunds', 'Stowmarket -> Bury St Edmunds', 40)],\n",
    "    'Harwich': [('Chelmsford', 'Harwich -> Chelmsford', 55)],\n",
    "    'Yarmouth': [('Lowestoft', 'Yarmouth -> Lowestoft', 45)],\n",
    "    'Caister': [('Great Yarmouth', 'Caister -> Great Yarmouth', 30)],\n",
    "    'Ely': [('Cambridge', 'Ely -> Cambridge', 30)]\n",
    "}\n",
    "\n",
    "instance = Graph(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe80a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(graph, node_color='skyblue', seed=1):\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Iterate through each node and its successors in the graph\n",
    "    for node, successors in graph.items():\n",
    "        for successor in successors:\n",
    "            successor_node, action, cost = successor\n",
    "            ''' Add an edge from the current node to its successor\n",
    "                with action and cost attributes '''\n",
    "            G.add_edge(node, successor_node, action=action, weight=cost)\n",
    "\n",
    "    # Compute the layout of the graph using spring layout\n",
    "    pos = nx.spring_layout(G, seed=seed, k=9) \n",
    "    \n",
    "    # Create a new figure\n",
    "    plt.figure(figsize=(12, 22))\n",
    "    \n",
    "    # Draw the graph with nodes labeled\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_color, node_size=1000, font_size=10, font_weight='bold',\n",
    "            edge_color='gray', arrowsize=20, connectionstyle='arc3,rad=0.1')\n",
    "\n",
    "    # Adding labels (actions and costs) to the edges\n",
    "    labels = {(u, v): f\"{d['action']} ({d['weight']})\" for u, v, d in G.edges(data=True)}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels, font_color='green')\n",
    "\n",
    "    # Display the graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87662efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_graph(structure, seed = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the paths as a string\n",
    "def extract_path(node):\n",
    "    path = []\n",
    "    while node.parent is not None:\n",
    "        path.insert(0, node.state)\n",
    "        node = node.parent\n",
    "    path.insert(0, node.state)\n",
    "    return \" -> \".join(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic values\n",
    "heuristic_structure_value = {\n",
    "    'Ipswich': 70,\n",
    "    'Colchester': 40,\n",
    "    'Norwich': 100,\n",
    "    'Bury St Edmunds': 50,\n",
    "    'Chelmsford': 30,\n",
    "    'Lowestoft': 120,\n",
    "    'Great Yarmouth': 130,\n",
    "    'Cambridge': 60,\n",
    "    'London': 20,\n",
    "    'Felixstowe': 70,\n",
    "    'Thetford': 110,\n",
    "    'Stowmarket': 60,\n",
    "    'Harwich': 90,\n",
    "    'Yarmouth': 105,\n",
    "    'Caister': 120,\n",
    "    'Ely': 90\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d557253-230f-468f-bda4-0be77906d7ab",
   "metadata": {},
   "source": [
    "Task 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bc5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform Cost Search - Searches the nodes with the lowest cost first.\n",
    "\n",
    "def ucs(start, goal, graph):\n",
    "\n",
    "    # Keep track of the history of visited states and the history of frontier content\n",
    "    frontier_history = []\n",
    "    node_history = []\n",
    "\n",
    "    frontier = PriorityQueue()\n",
    "    node_start = Node(start, None, None, 0)\n",
    "    frontier.put((0, node_start))  # Using a priority queue with path cost as the priority\n",
    "    explored = {}  # Using a dictionary to keep track of the visited state (lowest cost found for each state)\n",
    "    \n",
    "    while not frontier.empty():\n",
    "\n",
    "        # Add the current frontier to the history\n",
    "        frontier_history.append([extract_path(node) for (cost, node) in frontier.queue])\n",
    "\n",
    "        _, node = frontier.get()  # Get the node with the lowest path cost\n",
    "        node_history.append(node.state)\n",
    "\n",
    "        if node.state == goal:\n",
    "            return node, node_history, frontier_history # Return the goal node if found\n",
    "        \n",
    "        # If the state is not explored or has a lower cost in the explored set, add it to the explored set\n",
    "        if node.state not in explored or node.path_cost < explored[node.state].path_cost:\n",
    "            explored[node.state] = node  # Update the explored set with the node\n",
    "\n",
    "            for child_state, action, step_cost in graph.successors(node.state):\n",
    "                child_node = Node(child_state, node, action, node.path_cost + step_cost)\n",
    "                # If the child state is not explored or has a lower cost in the explored set, add it to the frontier\n",
    "                if child_state not in explored or child_node.path_cost < explored[child_state].path_cost:\n",
    "                    frontier.put((child_node.path_cost, child_node))\n",
    "    \n",
    "    # No solution found\n",
    "    print(\"Couldn't find the goal state!\")\n",
    "\n",
    "    return None, node_history, frontier_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76c4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucs_sol, ucs_node_history, ucs_frontier_history = ucs('Ipswich', 'Ely', instance)\n",
    "extract_path(ucs_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCS explored the following states in the the presented order\n",
    "for i, n in enumerate(ucs_node_history):\n",
    "    if i < (len(ucs_node_history)-1):\n",
    "        print(f'{n}', end = \" -> \")\n",
    "    else:\n",
    "        print(f'{n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every step in the fringe\n",
    "for i, fringe in enumerate(ucs_frontier_history):\n",
    "    print(f'* At time step {i}, the fringe contained: {fringe}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157dd0f5-6819-46b1-846d-d0013d7d8e4e",
   "metadata": {},
   "source": [
    "Task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd87a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greedy Search (GS) - find the path from the start state to the goal state in a graph, using a provided heuristic function.\n",
    "\n",
    "def greedySearch(start, goal, graph, heuristic):\n",
    "    \n",
    "    # Keep track of the history of visited states and the history of frontier content\n",
    "    frontier_history = []\n",
    "    node_history = []\n",
    "    \n",
    "    frontier = PriorityQueue()\n",
    "    frontier.put((heuristic[start], Node(start, None, None, 0))) \n",
    "    explored = {}  # Using a dictionary to keep track of the lowest cost found for each state\n",
    "\n",
    "    while not frontier.empty():\n",
    "\n",
    "        # Add the current frontier to the history\n",
    "        frontier_history.append([extract_path(node) for (cost, node) in frontier.queue])\n",
    "\n",
    "        _, node = frontier.get()  # Get the node with the lowest path cost\n",
    "        node_history.append(node.state)\n",
    "\n",
    "        if node.state == goal:\n",
    "            return node, node_history, frontier_history # Return the goal node if found\n",
    "        \n",
    "        # If the state is not explored, add it to the explored set\n",
    "        if node.state not in explored:\n",
    "            explored[node.state] = heuristic[node.state]  # Update the explored set with the node\n",
    "\n",
    "            for child_state, action, step_cost in graph.successors(node.state):\n",
    "                child_node = Node(child_state, node, action, node.path_cost + step_cost)\n",
    "                # If the child state is not explored, add it to the frontier\n",
    "                if child_state not in explored:\n",
    "                    h = heuristic[child_state]\n",
    "                    frontier.put((h, child_node))\n",
    "    \n",
    "    # No solution found\n",
    "    print(\"Couldn't find the goal state!\")\n",
    "\n",
    "    return None, node_history, frontier_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c97dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedySearch_sol, greedySearch_node_history, greedySearch_frontier_history = greedySearch('Ipswich', 'Ely', instance, heuristic_structure_value)\n",
    "extract_path(greedySearch_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GS explored the following states in the the presented order\n",
    "for i, n in enumerate(greedySearch_node_history):\n",
    "    if i < (len(greedySearch_node_history)-1):\n",
    "        print(f'{n}', end = \" -> \")\n",
    "    else:\n",
    "        print(f'{n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every step in the fringe\n",
    "for i, fringe in enumerate(greedySearch_frontier_history):\n",
    "    print(f'* At time step {i}, the fringe contained: {fringe}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61865820-a0d9-422c-ae70-33aacd8c6ca1",
   "metadata": {},
   "source": [
    "Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e5c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A* Search - to find the path from the start state to the goal state in a graph, using node cost and \n",
    "a provided heuristic function.\n",
    "'''\n",
    "\n",
    "def aStarSearch(start, goal, graph, heuristic):\n",
    "\n",
    "    # Keep track of the history of visited states and the history of frontier content\n",
    "    frontier_history = []\n",
    "    node_history = []\n",
    "    \n",
    "    frontier = PriorityQueue()\n",
    "    start_node = Node(start, None, None, 0)\n",
    "    frontier.put((heuristic[start], start_node)) \n",
    "    explored = {}  # Using a dictionary to keep track of the lowest cost found for each state\n",
    "\n",
    "    while not frontier.empty():\n",
    "\n",
    "        # Add the current frontier to the history\n",
    "        frontier_history.append([extract_path(node) for (cost, node) in frontier.queue])\n",
    "\n",
    "        _, node = frontier.get()  # Get the node with the lowest path cost\n",
    "        node_history.append(node.state)\n",
    "\n",
    "        if node.state == goal:\n",
    "            return node, node_history, frontier_history # Return the goal node if found\n",
    "        \n",
    "        # If the state is not explored, add it to the explored set\n",
    "        if node.state not in explored:\n",
    "            explored[node.state] = node.path_cost  # Update the explored set with the node\n",
    "\n",
    "            for child_state, action, step_cost in graph.successors(node.state):\n",
    "                child_node = Node(child_state, node, action, node.path_cost + step_cost)\n",
    "                # If the child state is not explored or has a lower cost in the explored set, add it to the frontier\n",
    "                if child_state not in explored or child_node.path_cost < explored[child_state]:\n",
    "                    h = heuristic[child_state]\n",
    "                    frontier.put((child_node.path_cost + h, child_node))\n",
    "    \n",
    "    # No solution found\n",
    "    print(\"Couldn't find the goal state!\")\n",
    "\n",
    "    return None, node_history, frontier_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aStarSearch_sol, aStarSearch_node_history, aStarSearch_frontier_history = aStarSearch('Ipswich', 'Ely', instance, heuristic_structure_value)\n",
    "extract_path(aStarSearch_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A* explored the following states in the the presented order\n",
    "for i, n in enumerate(aStarSearch_node_history):\n",
    "    if i < (len(aStarSearch_node_history)-1):\n",
    "        print(f'{n}', end = \" -> \")\n",
    "    else:\n",
    "        print(f'{n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every step in the fringe\n",
    "for i, fringe in enumerate(aStarSearch_frontier_history):\n",
    "    print(f'* At time step {i}, the fringe contained: {fringe}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d72b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b81056dd-e055-4de3-9e59-294b5fa60b71",
   "metadata": {},
   "source": [
    "Task 2 - Bayesian Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1caadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bayesian network structure\n",
    "travel_BN = BayesianNetwork([\n",
    "    (\"Age\", \"Education\"), \n",
    "    (\"Sex\", \"Education\"), \n",
    "    (\"Education\", \"Residence\"), \n",
    "    (\"Education\", \"Occupation\"),\n",
    "    (\"Residence\", \"Travel\"),\n",
    "    (\"Occupation\", \"Travel\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064f350-cfe5-49ef-bfc8-6bcc426593ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the Expert-based network\n",
    "\n",
    "# Create a new graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add the nodes and edges to the graph\n",
    "G.add_nodes_from(travel_BN.nodes())\n",
    "G.add_edges_from(travel_BN.edges())\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(G, with_labels=True, node_color='skyblue', edge_color='gray')\n",
    "\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f70677-50d8-41b6-acb2-0b6ca6b40351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Travel_data dataset\n",
    "travel_data = pd.read_csv('Travel_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c1726f-351b-4f89-b43b-e3f4f45f2a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hill-Climbing and K2Score used together to learn the structure of the network\n",
    "scoring_method = K2Score(data = travel_data)\n",
    "est = HillClimbSearch(data = travel_data)\n",
    "estimated_model = est.estimate(scoring_method=scoring_method, max_indegree=3, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348a2c9-38cf-4101-a140-84bf7590141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to evaluate the learned model structures.\n",
    "def find_f1_score(estimated_model, true_model):\n",
    "    nodes = estimated_model.nodes()\n",
    "    est_adj = nx.to_numpy_array(estimated_model.to_undirected(), nodelist=nodes, weight=None)\n",
    "    true_adj = nx.to_numpy_array(true_model.to_undirected(), nodelist=nodes, weight=None)\n",
    "    f1 = f1_score(np.ravel(true_adj), np.ravel(est_adj))\n",
    "    print(\"F1-score:\", round(f1, 3))\n",
    "\n",
    "find_f1_score(estimated_model, travel_BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b332149-916a-47cc-90ad-949514cc0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the learned network\n",
    "\n",
    "# Create a new graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add the nodes and edges to the graph\n",
    "G.add_nodes_from(estimated_model.nodes())\n",
    "G.add_edges_from(estimated_model.edges())\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(G, with_labels=True, node_color='lightgreen', edge_color='gray')\n",
    "\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bbeb53-3a84-49de-adf2-084c89b9fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script learns the parameters of a Bayesian network from data\n",
    "# Converts the learned network to a BayesianNetwork class object\n",
    "estimated_model = BayesianNetwork(estimated_model)\n",
    "\n",
    "# Learn the parameters of the network from the data\n",
    "estimated_model.fit(travel_data)\n",
    "\n",
    "# Print the learned parameters\n",
    "for cpd in estimated_model.get_cpds():\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956b8bf-3009-42ba-b316-9b86d499db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between age groups and usage of travel modes.\n",
    "infer = VariableElimination(estimated_model)\n",
    "q_1 = infer.query(variables = ['Age', 'Travel'],\n",
    "                evidence = None, # No evidence varibales\n",
    "                elimination_order = \"MinFill\", # Can also use \"greedy\" for example\n",
    "                show_progress = False)\n",
    "print(\"Inference for Age and Travel:\")\n",
    "print(q_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58ba5b-acf1-4cb1-a535-4764db6f0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between males and females of travel modes\n",
    "infer = VariableElimination(estimated_model)\n",
    "q_2 = infer.query(variables = ['Sex', 'Travel'],\n",
    "                evidence = None, # No evidence varibales\n",
    "                elimination_order = \"MinFill\",\n",
    "                show_progress = False)\n",
    "print(\"Inference for Sex and Travel:\")\n",
    "print(q_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308ce5c-2621-40c1-ba5d-eef4e85504ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between males of travel mode\n",
    "infer = VariableElimination(estimated_model)\n",
    "q_males = infer.query(variables = ['Travel'],\n",
    "                evidence = {'Sex': 'M'}, \n",
    "                elimination_order = \"MinFill\",\n",
    "                show_progress = False)\n",
    "print(\"Inference for Males and Travel:\")\n",
    "print(q_males)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56941ae-32cf-4658-91b5-37a0a2788c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between females of travel mode\n",
    "infer = VariableElimination(estimated_model)\n",
    "q_females = infer.query(variables = ['Travel'],\n",
    "                evidence = {'Sex': 'F'}, \n",
    "                elimination_order = \"MinFill\",\n",
    "                show_progress = False)\n",
    "print(\"Inference for Females and Travel:\")\n",
    "print(q_females)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c19d9df-c9b1-4190-bb2a-4d17cf90024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters of Bayesian Network\n",
    "travel_BN.fit(travel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeed482-f605-4042-84d6-da265af5454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the results from the expert-based and learned models\n",
    "def compare_inferences(model1, model2, evidence, variables):\n",
    "    infer1 = VariableElimination(model1)\n",
    "    infer2 = VariableElimination(model2)\n",
    "    result1 = infer1.query(variables=variables, evidence=evidence)\n",
    "    result2 = infer2.query(variables=variables, evidence=evidence)\n",
    "    print(f\"Results for evidence {evidence}:\")\n",
    "    print(\"Expert-based model:\")\n",
    "    print(result1)\n",
    "    print(\"Learned model:\")\n",
    "    print(result2)\n",
    "    \n",
    "# Check the comparisons of given variables\n",
    "compare_inferences(travel_BN, estimated_model, evidence={'Sex': 'M'}, variables=['Travel'])\n",
    "compare_inferences(travel_BN, estimated_model, evidence={'Age': 'young'}, variables=['Travel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d84b8d-589d-4084-bad9-42322a3a6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(travel_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c40806-3e8d-408f-a620-9ce96ef3787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models on the training data\n",
    "travel_BN.fit(train_data)\n",
    "estimated_model.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9fb9d-af30-48b5-9740-1b9164c473e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on the data using BIC score\n",
    "expert_score = BicScore(test_data).score(travel_BN)\n",
    "learned_score = BicScore(test_data).score(estimated_model)\n",
    "\n",
    "print(f\"Expert-based model BIC score: {round(expert_score, 2)}\")\n",
    "print(f\"Learned model BIC score: {round(learned_score, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b2696-e575-4eac-b1ee-d372db50a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which model is more accurate\n",
    "if learned_score < expert_score:\n",
    "    print(\"The learned model predicts the travel data more accurately.\")\n",
    "else:\n",
    "    print(\"The expert-based model predicts the travel data more accurately.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a0d23-fc8e-49a0-8a2a-f789300ba2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1881224-7097-4b7d-a58b-bec27d8e06b7",
   "metadata": {},
   "source": [
    "Task 3 â€“ Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a7126-67bd-493a-b14e-4129dc3dd6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv('twitter_train.csv')\n",
    "test_data = pd.read_csv('twitter_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f54d0-f10e-401a-ade6-291fc1eeb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the datasets from twitter_train.csv\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564d028-144d-447e-b174-603b8321a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the datasets from twitter_test.csv\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf97005-3188-4315-8d5e-60d82de1bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the text\n",
    "def clean_data(text):\n",
    "    text = \"\".join([char.lower() for char in text if char not in string.punctuation]) # Remove punctuation\n",
    "    tokens = re.split(r'\\W+', text) # Tokenize\n",
    "    ps = nltk.PorterStemmer() # Remove stem\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stopword_list = stopwords.words('english') \n",
    "    text = [ps.stem(word) for word in tokens if word not in stopword_list]\n",
    "    return text\n",
    "\n",
    "# Apply it to the whole dataset\n",
    "train_data['clean text'] = train_data['text'].apply(clean_text)\n",
    "test_data['clean text'] = test_data['text'].apply(clean_text)\n",
    "\n",
    "# Display the resulting datasets\n",
    "print(\"twitter_train.csv:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\n\\ntwitter_test.csv:\")\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81757abb-cee0-41d3-9382-87513e923bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise CountVectoriser based on the text cleaning function\n",
    "count_vect = CountVectorizer(analyzer=clean_data, max_features=3000)\n",
    "\n",
    "# Create the document-term matrix based on counts\n",
    "X_train_counts = count_vect.fit_transform(train_data['clean text'])\n",
    "X_test_counts = count_vect.fit_transform(test_data['clean text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ab14f-1248-46c5-8541-655240bb3b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "y_train = train_data['sentiment']\n",
    "y_test = test_data['sentiment']\n",
    "\n",
    "# Initialise Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Explores the parameters\n",
    "parameters = {'alpha': [0.1, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "# Grid search\n",
    "np.random.seed(0) # shows same results everytime it runs\n",
    "\n",
    "grid_search = GridSearchCV(nb, parameters, cv=5, scoring = 'f1_micro', n_jobs=-1)  # Evaluate F1-score\n",
    "grid_search_fit = grid_search.fit(X_train_counts, y_train)\n",
    "pd.DataFrame(grid_search_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65daed-11e0-45b7-9fec-796a4fab8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes model with the best parameters from grid search\n",
    "best_nb = grid_search_fit.best_estimator_\n",
    "best_nb.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ad164-a488-483d-bf62-db22aa8f1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training set\n",
    "train_pred = best_nb.predict(X_train_counts)\n",
    "print('Naive Bayes - Overall accuracy on training set:', round(accuracy_score(y_train, train_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7de980-21f1-45bd-8372-798e8f2ec31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_pred = best_nb.predict(X_test_counts)\n",
    "precision_nb, recall_nb, fscore_nb, _ = score(y_test, test_pred, pos_label='negative', average='binary')\n",
    "accuracy_nb = accuracy_score(y_test, test_pred)\n",
    "print('Naive Bayes - Accuracy: {} / Precision: {} / Recall: {} / F1-score: {}'.format(\n",
    "    round(accuracy_nb, 3),\n",
    "    round(precision_nb, 3),\n",
    "    round(recall_nb, 3),\n",
    "    round(fscore_nb, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442bdc7-d59a-4020-89ee-3f7bc2b681df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the calculated graph\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, test_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92f9347-32de-4602-808e-1d27db121456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Logistic Regression for comparison\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_counts, y_train)\n",
    "y_pred_lr = lr.predict(X_test_counts)\n",
    "\n",
    "precision_lr, recall_lr, fscore_lr, _ = score(y_test, y_pred_lr, pos_label='negative', average='binary')\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "\n",
    "print('Logistic Regression - Accuracy: {} / Precision: {} / Recall: {} / F1-score: {}'.format(\n",
    "    round(accuracy_lr, 3),\n",
    "    round(precision_lr, 3),\n",
    "    round(recall_lr, 3),\n",
    "    round(fscore_lr, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c6c69-68d2-44a0-a7e2-e8bbb31e6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the calculated graph\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_lr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2253ca-6bcc-400b-8a5b-5c13a643e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare both models\n",
    "print(\"Model Comparison:\")\n",
    "print(f\"Naive Bayes - Accuracy: {round(accuracy_nb, 3)}, Precision: {round(precision_nb, 3)}, Recall: {round(recall_nb, 3)}, F1-score: {round(fscore_nb,3)}\")\n",
    "print(f\"Logistic Regression - Accuracy: {round(accuracy_lr, 3)}, Precision: {round(precision_lr, 3)}, Recall: {round(recall_lr, 3)}, F1-score: {round(fscore_lr, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff10a7-24a4-48e6-a2a0-a726638366d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare both models using accuracy\n",
    "if accuracy_lr > accuracy_nb:\n",
    "    print(\"Logistic Regression is more accurate than Naive Bayes.\")\n",
    "elif accuracy_lr < accuracy_nb:\n",
    "    print(\"Naive Bayes is more accurate than Logistic Regression.\")\n",
    "else:\n",
    "    print(\"Both models have the same accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf1f04-b47c-4b9b-a9ea-0a15eb2a2754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
